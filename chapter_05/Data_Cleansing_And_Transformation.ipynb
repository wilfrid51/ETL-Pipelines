{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69c1fcd9",
   "metadata": {},
   "source": [
    "## Data Cleansing and Transformation in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ada6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2a0bdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7450c27e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f074851e",
   "metadata": {},
   "source": [
    "### Writing Transformation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a246c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transformed_data(crash_file, vehcile_file): \n",
    "\n",
    "    # import data\n",
    "    df_crashes = pd.read_csv(f\"data/{crash}\") \n",
    "    df_vehicles= pd.read_csv(f\"data/{vehcile_file}\") \n",
    "\n",
    " \n",
    "\n",
    "    under_threshold_removed = df_crashes.dropna(axis='index', thresh=2, inplace=False) \n",
    "    under_threshold_rows = df_crashes[~df_crashes.index.isin(under_threshold_removed.index)] \n",
    "    df_crashes.fillna(value={'report_type': 'ON SCENE'}, inplace=True) \n",
    "\n",
    "   \n",
    "\n",
    "    df = df_crashes.merge(df_vehicles, how = 'left',on='crash_record_id',suffixes=('_left', '_right')) \n",
    "    df_agg = df.groupby('vehicle_type').agg({'crash_record_id': 'count'}).reset_index()  \n",
    "\n",
    "    \n",
    "    number_of_passenger_cars_involved = df_agg[df_agg['vehicletypes'] == 'PASSENGER']['crash_record_id'].array[0] \n",
    "\n",
    "\n",
    "\n",
    "    df = df.rename(columns = vehicle_mapping)  \n",
    "\n",
    "    vehicle_mapping = {'vehicle_type' :  'vehicletypes'}  \n",
    "\n",
    "    df = df.rename(columns= vehicle_mapping) \n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99898696",
   "metadata": {},
   "source": [
    "The preceding code can be split into reusable functions that are easy to manage as follows:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9656323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from data source  \n",
    "def read_datasources(source_name): \n",
    "    df = pd.read_csv(f\"data/{source_name}\")  \n",
    "    return df \n",
    "\n",
    "# Drop rows with null values \n",
    "def drop_rows_with_null_values(df): \n",
    "    under_threshold_removed = df.dropna(axis='index', thresh=2, inplace=False)  \n",
    "    df = df[~df.index.isin(under_threshold_removed.index)]  \n",
    "    return df \n",
    "\n",
    "# Fill missing values \n",
    "def fill_missing_values(df): \n",
    "    df = df.fillna(value={'report_type': 'ON SCENE'})  \n",
    "    return df \n",
    "\n",
    "# Merge Dataframes \n",
    "def merge_dataframes(df_vehicles,df_crashes ): \n",
    "    df = df_crashes.merge(df_vehicles,how='left', on='crash_record_id', suffixes=('_left', '_right'))  \n",
    "    return df "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37d26c6",
   "metadata": {},
   "source": [
    "### Running the Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f8953d",
   "metadata": {},
   "source": [
    "Define the Pipeline Functions to run the Cleansing and Transformation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20248c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_pipeline(crash_file, vehicle_crash_file): \n",
    "    df_crash = pd.DataFrame() \n",
    "    df_vehicle_crash = pd.DataFrame() \n",
    "    try: \n",
    "        df_crash = read_datasources(crash_file) \n",
    "        df_vehicle_crash = read_datasources(vehicle_crash_file) \n",
    "    except Exception as e: \n",
    "        logging.info(\"Exception in reading data pipeline\") \n",
    "    finally: \n",
    "        return df_crash, df_vehicle_crash \n",
    " \n",
    " \n",
    "def drop_rows_with_null_values_pipeline(df_crash, df_vehicle_crash): \n",
    "    try: \n",
    "        df_crash = drop_rows_with_null_values(df_crash) \n",
    "        df_vehicle_crash = drop_rows_with_null_values(df_vehicle_crash) \n",
    "    except Exception as e: \n",
    "        logging.info(\"Exception in dropping rows with null value data pipeline\") \n",
    " \n",
    "    finally: \n",
    "        return df_crash, df_vehicle_crash \n",
    " \n",
    " \n",
    "def fill_missing_values_pipeline(df_crash, df_vehicle_crash): \n",
    "    try: \n",
    "        df_crash = fill_missing_values(df_crash) \n",
    "        df_vehicle_crash = fill_missing_values(df_vehicle_crash) \n",
    "    except Exception as e: \n",
    "        logging.info(\"Exception in filling missing value pipeline\") \n",
    " \n",
    "    finally: \n",
    "        return df_crash, df_vehicle_crash \n",
    " \n",
    " \n",
    "def merge_dataframes_pipeline(df_crash, df_vehicle_crash): \n",
    "    try: \n",
    "        df_crash = fill_missing_values(df_crash) \n",
    "        df_vehicle_crash = fill_missing_values(df_vehicle_crash) \n",
    "    except Exception as e: \n",
    "        logging.info(\"Exception in merge dataframes pipeline\") \n",
    " \n",
    "    finally: \n",
    "        return df_crash, df_vehicle_crash "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891dc164",
   "metadata": {},
   "source": [
    "Use the Chigaco Traffic Data and Run the Pipeline Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3e2758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input data \n",
    "crash_data_file = \"traffic_crashes.csv\" \n",
    "vehicle_crash_data_file = \"traffic_crash_vehicle.csv\" \n",
    "\n",
    "# Read Data Pipeline\n",
    "df_crash, df_vehicle_crash = read_data_pipeline(\"traffic_crashes.csv\", \"traffic_crash_vehicle.csv\")\n",
    "\n",
    "# Drop Nulls\n",
    "df_crash, df_vehicle_crash = drop_rows_with_null_values_pipeline(df_crash, df_vehicle_crash) \n",
    "\n",
    "# Fill in Missing Values\n",
    "df_crash, df_vehicle_crash = fill_missing_values_pipeline(df_crash, df_vehicle_crash) \n",
    "\n",
    "# Merge Dataframes\n",
    "df_crash, df_vehicle_crash = merge_dataframes_pipeline(df_crash, df_vehicle_crash)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829e3d45",
   "metadata": {},
   "source": [
    "### Transformation Activities in Python "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165c0b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "READING_CRASH_DATA_PIPELINE = \"<NOT_EXECUTED>\" \n",
    "DROPPING_ROW_WITH_NULL_PIPELINE = \"<NOT_EXECUTED>\" \n",
    "FILLING_MISSING_VALUE_PIPELINE = \"<NOT_EXECUTED>\" \n",
    "MERGE_DATAFRAME_PIPELINE = \"<NOT_EXECUTED>\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00cd6a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crash, df_vehicle_crash = read_data_pipeline(\"traffic_crashes.csv\", \"traffic_crash_vehicle.csv\") \n",
    " \n",
    "if READING_CRASH_DATA_PIPELINE == \"<OK>\": \n",
    "    df_crash, df_vehicle_crash = drop_rows_with_null_values_pipeline(df_crash, df_vehicle_crash) \n",
    " \n",
    "if DROPPING_ROW_WITH_NULL_PIPELINE == \"<OK>\": \n",
    "    df_crash, df_vehicle_crash = fill_missing_values_pipeline(df_crash, df_vehicle_crash) \n",
    " \n",
    "if FILLING_MISSING_VALUE_PIPELINE == \"<OK>\": \n",
    "    df_crash, df_vehicle_crash = merge_dataframes_pipeline(df_crash, df_vehicle_crash) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14dbf8f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
